{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_pytorch_tutorial.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Pytorch Tutorial\n",
        "Reference : https://tutorials.pytorch.kr/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py\n",
        "\n",
        "### 설치 \n",
        "1. 가용 GPU의 CUDA 버전 확인!\n",
        "\n",
        "  (ex) nvcc -V\n",
        "\n",
        "2. https://pytorch.org/ 에서 버전에 맞는 설치 커맨드 확인\n",
        "\n",
        "  (ex) pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116\n",
        "\n",
        "3. 사용할 (가상)환경에서 커맨드 실행\n",
        "\n",
        "--------------------------------------------\n",
        "\n",
        "### 텐서 (Tensor)\n",
        "텐서(Tensor) : 배열(array)이나 행렬(matrix)와 매우 유사한 특수한 자료구조\n",
        "GPU나 다른 연산 가속을 위한 하드웨어서 실행가능.\n",
        "\n",
        "* 배열(array)이나 행렬(matrix)와 매우 유사한 특수한 자료구조\n",
        "* GPU나 다른 연산 가속을 위한 하드웨어서 실행가능.\n",
        "* Numpy의 ndarray와 매우 유사함"
      ],
      "metadata": {
        "id": "UXmz9oJ71KvI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OZ3me6n0zd85",
        "outputId": "f1296b4d-a355-4118-e1c5-e339b81181cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2021 NVIDIA Corporation\n",
            "Built on Sun_Feb_14_21:12:58_PST_2021\n",
            "Cuda compilation tools, release 11.2, V11.2.152\n",
            "Build cuda_11.2.r11.2/compiler.29618528_0\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "!nvcc -V"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서와 numpy 배열 사용을 위한 모듈 임포트(import)\n",
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "fbpqqjc-27zQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [1] 텐서 초기화\n",
        "[1-1] 데이터로부터 직접 생성하기\n",
        "이때, 텐서의 자료형(data type)은 데이터로부터 자동으로 유추하여 생성합니다."
      ],
      "metadata": {
        "id": "jcXHBSNS3Oqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [[1, 2], [3, 4]]\n",
        "x_data = torch.tensor(data)\n",
        "print(x_data.type())"
      ],
      "metadata": {
        "id": "HVWSY8hc271d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b86a2cc-32da-4564-a4ff-1111c3afeb37"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.LongTensor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data2 = [[1.2, 2.6], [3.4, 4.2]]\n",
        "x_data2 = torch.tensor(data2)\n",
        "print(x_data2.type())"
      ],
      "metadata": {
        "id": "8Or_Zmoh273p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "280b74df-fae2-44ba-8ffd-2db4f33e00b9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.FloatTensor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[1-2] NumPy 배열로부터 생성하기\n",
        "\n",
        "텐서는 NumPy 배열로 생성할 수 있습니다. (그 반대도 가능합니다.)\n"
      ],
      "metadata": {
        "id": "-y63iCsz5fr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)\n",
        "print(\"data\", data)\n",
        "print(x_np)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJA9MArg2777",
        "outputId": "c0233b4d-b172-4ffb-e94d-b45b3d1cd0d8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data [[1, 2], [3, 4]]\n",
            "tensor([[1, 2],\n",
            "        [3, 4]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.ones(5)\n",
        "print(f\"t: {t}\")\n",
        "n = t.numpy()\n",
        "print(f\"n: {n}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tb_Q4PTV5l3C",
        "outputId": "3f1e405a-6a4a-46fa-c08b-c3088691732d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([1., 1., 1., 1., 1.])\n",
            "n: [1. 1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[1-3] 다른 텐서로부터 생성하기\n",
        "\n",
        "명시적으로 재정의(override)하지 않는다면, 인자로 주어진 텐서의 속성(모양(shape), 자료형(datatype))을 유지합니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "YXUNacXr1Ww9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Original Tensor: \\n {x_data} \\n\")\n",
        "\n",
        "x_ones = torch.ones_like(x_data) # x_data의 속성을 유지합니다.\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "x_ones = torch.ones_like(x_data, dtype=torch.float) # x_data의 속성을 덮어씁니다.\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float) # x_data의 속성을 덮어씁니다.\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEvoAPyc6f3i",
        "outputId": "6ea44cca-8a98-4511-8b93-206e015afe13"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tensor: \n",
            " tensor([[1, 2],\n",
            "        [3, 4]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1, 1],\n",
            "        [1, 1]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1., 1.],\n",
            "        [1., 1.]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.4251, 0.8740],\n",
            "        [0.3135, 0.7494]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[1-4] 무작위(random) 또는 상수(constant) 값을 사용하기\n",
        "\n",
        "shape 은 텐서의 차원(dimension)을 나타내는 튜플(tuple)로, 아래 함수들에서는 출력 텐서의 차원을 결정합니다."
      ],
      "metadata": {
        "id": "nL1tUwCh6wRw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shape = (2, 3,)\n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PFrKZrM6tg2",
        "outputId": "e0fd8df1-2eeb-4cf7-de9a-440aceb44a54"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Tensor: \n",
            " tensor([[0.6483, 0.6857, 0.8925],\n",
            "        [0.6768, 0.5822, 0.8033]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]]) \n",
            "\n",
            "Zeros Tensor: \n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [2] 텐서의 속성(Attribute)\n",
        "\n",
        "\n",
        "텐서의 속성은 텐서의 모양(shape), 자료형(datatype) 및 어느 장치에 저장되는지를 나타냅니다."
      ],
      "metadata": {
        "id": "bRuHzkcd64hH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.rand(3, 4)\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5Zi6aAm7T-Q",
        "outputId": "220acd47-1b95-4d28-e038-faa9863a7b73"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [3] 텐서 연산(Operation)\n",
        "\n",
        "전치(transposing), 인덱싱(indexing), 슬라이싱(slicing), 수학 계산, 선형 대수, 임의 샘플링(random sampling) 등, 100가지 이상의 텐서 연산이 존재합니다.\n",
        "\n",
        "각 연산들은 (일반적으로 CPU보다 빠른) GPU에서 실행할 수 있습니다. \n",
        "\n",
        "### 런타임 -> 런타임 유형 변경 -> GPU\n",
        "### 런타임 변경 후, 런타임-> 모두 실행"
      ],
      "metadata": {
        "id": "W-rQgr2Q7PkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU가 존재하면 텐서를 이동합니다\n",
        "if torch.cuda.is_available():\n",
        "  tensor = tensor.to('cuda:0')\n",
        "  print(f\"Device tensor is stored on: {tensor.device}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oc6V_UTP7cEP",
        "outputId": "bf7db93e-e015-499e-bc94-df93d51009b7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device tensor is stored on: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[3-1] NumPy식의 표준 인덱싱과 슬라이싱"
      ],
      "metadata": {
        "id": "1LGDtPum8akY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.ones(4, 4)\n",
        "print(\"4x4 tensor 값을 1로 초기화 \\n\", tensor)\n",
        "\n",
        "tensor[:,1] = 0\n",
        "print(\"\\n 모든 행의 1열 값을 0으로 바꾸기\\n\", tensor)\n",
        "\n",
        "tensor[0,:] = -1\n",
        "print(\"\\n 0열의 모든 행 값을 -1로 바꾸기\\n\", tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KdtffPg8Yfe",
        "outputId": "aa9b9060-7c87-4c15-b647-2d7b1655ff54"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4x4 tensor 값을 1로 초기화 \n",
            " tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n",
            "\n",
            " 모든 행의 1열 값을 0으로 바꾸기\n",
            " tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n",
            "\n",
            " 0열의 모든 행 값을 -1로 바꾸기\n",
            " tensor([[-1., -1., -1., -1.],\n",
            "        [ 1.,  0.,  1.,  1.],\n",
            "        [ 1.,  0.,  1.,  1.],\n",
            "        [ 1.,  0.,  1.,  1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[3-2] 텐서 합치기 \n",
        "\n",
        "torch.cat 을 사용하여 주어진 차원에 따라 일련의 텐서를 연결할 수 있습니다. "
      ],
      "metadata": {
        "id": "_27nF_4G8P3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor)\n",
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)     # 유사 : numpy.concatenate()\n",
        "print(\"\\n torch.cat\\n\", t1)\n",
        "\n",
        "t2 = torch.stack([tensor, tensor], dim=1)\n",
        "print(\"\\n torch.stack\\n\", t2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TScy_vJD9QfB",
        "outputId": "87312571-5bb3-4cf5-bcb2-889eaa81d612"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1., -1., -1., -1.],\n",
            "        [ 1.,  0.,  1.,  1.],\n",
            "        [ 1.,  0.,  1.,  1.],\n",
            "        [ 1.,  0.,  1.,  1.]])\n",
            "\n",
            " torch.cat\n",
            " tensor([[-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
            "        [ 1.,  0.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  0.,  1.,  1.],\n",
            "        [ 1.,  0.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  0.,  1.,  1.],\n",
            "        [ 1.,  0.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  0.,  1.,  1.]])\n",
            "\n",
            " torch.stack\n",
            " tensor([[[-1., -1., -1., -1.],\n",
            "         [-1., -1., -1., -1.]],\n",
            "\n",
            "        [[ 1.,  0.,  1.,  1.],\n",
            "         [ 1.,  0.,  1.,  1.]],\n",
            "\n",
            "        [[ 1.,  0.,  1.,  1.],\n",
            "         [ 1.,  0.,  1.,  1.]],\n",
            "\n",
            "        [[ 1.,  0.,  1.,  1.],\n",
            "         [ 1.,  0.,  1.,  1.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[3-3] 텐서 곱하기\n",
        "\n",
        "a.  요소별 곱(element-wise product)을 계산합니다"
      ],
      "metadata": {
        "id": "MeEzuRfs-AD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor1 = torch.ones(4, 4)\n",
        "tensor1[:,1] = 0\n",
        "tensor2 = torch.ones(4, 4)\n",
        "tensor2[:,2] = 0\n",
        "\n",
        "print(f\"tensor.mul(tensor) \\n {tensor1.mul(tensor2)} \\n\")\n",
        "# 다른 문법:\n",
        "print(f\"tensor * tensor \\n {tensor1 * tensor2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRM6a4K99Zi3",
        "outputId": "01b5d2c5-ef91-4c84-a3c5-4674539d265d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor.mul(tensor) \n",
            " tensor([[1., 0., 0., 1.],\n",
            "        [1., 0., 0., 1.],\n",
            "        [1., 0., 0., 1.],\n",
            "        [1., 0., 0., 1.]]) \n",
            "\n",
            "tensor * tensor \n",
            " tensor([[1., 0., 0., 1.],\n",
            "        [1., 0., 0., 1.],\n",
            "        [1., 0., 0., 1.],\n",
            "        [1., 0., 0., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. 두 텐서 간의 행렬 곱(matrix multiplication)을 계산합니다\n"
      ],
      "metadata": {
        "id": "eGNgeKl6-bYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"tensor.matmul(tensor.T) \\n {tensor1.matmul(tensor2)} \\n\")\n",
        "# 다른 문법:\n",
        "print(f\"tensor @ tensor.T \\n {tensor1 @ tensor2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nK3yi1cw-tNr",
        "outputId": "7928efad-e242-4a92-c8e8-0e2de6159e20"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor.matmul(tensor.T) \n",
            " tensor([[3., 3., 0., 3.],\n",
            "        [3., 3., 0., 3.],\n",
            "        [3., 3., 0., 3.],\n",
            "        [3., 3., 0., 3.]]) \n",
            "\n",
            "tensor @ tensor.T \n",
            " tensor([[3., 3., 0., 3.],\n",
            "        [3., 3., 0., 3.],\n",
            "        [3., 3., 0., 3.],\n",
            "        [3., 3., 0., 3.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[3-4] 바꿔치기(in-place) 연산 \n",
        "\n",
        "_ 접미사를 갖는 연산들은 바꿔치기(in-place) 연산입니다. \n",
        "\n",
        "예를 들어: x.copy_() 나 x.t_() 는 x 를 변경합니다.\n",
        "\n",
        "\n",
        "바꿔치기 연산은 메모리를 일부 절약하지만, 기록(history)이 즉시 삭제되어 도함수(derivative) 계산에 문제가 발생할 수 있습니다. \n",
        "\n",
        "따라서, 사용을 권장하지 않습니다."
      ],
      "metadata": {
        "id": "7J5VH5DX-2LH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"바꿔치기 연산 전 \\n\", tensor, \"\\n\")\n",
        "tensor.add_(5)\n",
        "print(\"바꿔치기 연산 후 \\n\", tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KgcGD6i-9Mi",
        "outputId": "41b4e68f-909e-4923-c000-1adbcf245527"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "바꿔치기 연산 전 \n",
            " tensor([[-1., -1., -1., -1.],\n",
            "        [ 1.,  0.,  1.,  1.],\n",
            "        [ 1.,  0.,  1.,  1.],\n",
            "        [ 1.,  0.,  1.,  1.]]) \n",
            "\n",
            "바꿔치기 연산 후 \n",
            " tensor([[4., 4., 4., 4.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[3-5] squeeze 연산\n",
        "\n",
        "tensor dimension 중 size 1인 dimension을 제거합니다.\n",
        "\n",
        "\n",
        "예를 들어, (A x 1 x B x 1 x C) shape을 가진 텐서에 squeeze 연산을 적용하면,\n",
        "(A x B x C) shape만 남게 됩니다.\n",
        "\n",
        "\n",
        "\n",
        "dimension을 지정해주면, 특정 dimension에만 적용가능합니다."
      ],
      "metadata": {
        "id": "uczVycguAXaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.zeros(2, 1, 2, 1, 2)\n",
        "print(\" squeeze 연산 전 : \\n\", x.shape)\n",
        "\n",
        "y = torch.squeeze(x)\n",
        "print(\"\\n squeeze 연산 후 : \\n\", y.shape)\n",
        "\n",
        "z = torch.squeeze(x, dim=1)\n",
        "print(\"\\n 특정 dimension에만 squeeze 연산 후 : \\n\", z.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nN_ve-4_A2XK",
        "outputId": "bc230aba-3666-469d-d920-d8872b048932"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " squeeze 연산 전 : \n",
            " torch.Size([2, 1, 2, 1, 2])\n",
            "\n",
            " squeeze 연산 후 : \n",
            " torch.Size([2, 2, 2])\n",
            "\n",
            " 특정 dimension에만 squeeze 연산 후 : \n",
            " torch.Size([2, 2, 1, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[3-6] unsqueeze 연산\n",
        "\n",
        "특정 위치에 크기가 1인 텐서를 생성합니다."
      ],
      "metadata": {
        "id": "dBwBrpVECCZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1, 2, 3, 4])\n",
        "print(\" unsqueeze 연산 전 : \\n\", x.shape)\n",
        "\n",
        "\n",
        "y = torch.unsqueeze(x, dim=0)\n",
        "print(\"\\n dimension 0에 unsqueeze 연산 후 : \\n\", y.shape)\n",
        "\n",
        "\n",
        "z = torch.unsqueeze(x, dim=1)\n",
        "print(\"\\n dimension 1에 unsqueeze 연산 후 : \\n\", z.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73JjfG_CCUIU",
        "outputId": "23de2fde-69b3-425e-d4f4-092700905842"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " unsqueeze 연산 전 : \n",
            " torch.Size([4])\n",
            "\n",
            " dimension 0에 unsqueeze 연산 후 : \n",
            " torch.Size([1, 4])\n",
            "\n",
            " dimension 1에 unsqueeze 연산 후 : \n",
            " torch.Size([4, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [4] NumPy 변환(Bridge)\n",
        "\n",
        "CPU 상의 텐서와 NumPy 배열은 메모리 공간을 공유하기 때문에, 하나를 변경하면 다른 하나도 변경됩니다.\n",
        "\n",
        "\n",
        "[4-1] 텐서를 NumPy 배열로 변환하기"
      ],
      "metadata": {
        "id": "cMAQ3Z3X8HoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.ones(5)\n",
        "print(f\"tensor t:\\n {t}\\n\")\n",
        "n = t.numpy()\n",
        "print(f\"numpy n:\\n {n}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfBkvK8l-aqa",
        "outputId": "41c88e37-86c1-4565-cded-56cd234bd724"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor t:\n",
            " tensor([1., 1., 1., 1., 1.])\n",
            "\n",
            "numpy n:\n",
            " [1. 1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[4-2] 텐서의 변경 사항이 NumPy 배열에 반영됩니다."
      ],
      "metadata": {
        "id": "m4VnSL6R_lGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t.add_(1)\n",
        "print(f\"tensor t:\\n {t}\")\n",
        "print(f\"numpy n:\\n {n}\")\n",
        "\n",
        "## Exercise : t를 CUDA tensor로 만들고, 어떤 차이가 있는지 살펴보자\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4jrc_Ve_zSx",
        "outputId": "86837df2-e5d5-4f8e-a630-96cc463943e4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor t:\n",
            " tensor([2., 2., 2., 2., 2.])\n",
            "numpy n:\n",
            " [2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[4-3] NumPy 배열을 텐서로 변환하기"
      ],
      "metadata": {
        "id": "594HvU1J_5iM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = np.ones(5)\n",
        "print(f\"numpy n:\\n {n}\\n\")\n",
        "t = torch.from_numpy(n)\n",
        "print(f\"tensor t:\\n {t}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4Ikz5ky_1FQ",
        "outputId": "9868d343-c30e-46c9-9e0e-7c257ee853e5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy n:\n",
            " [1. 1. 1. 1. 1.]\n",
            "\n",
            "tensor t:\n",
            " tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[4-4] NumPy 배열의 변경 사항이 텐서에 반영됩니다."
      ],
      "metadata": {
        "id": "e60ftL9AADab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.add(n, 1, out=n)\n",
        "print(f\"tensor t:\\n {t}\")\n",
        "print(f\"numpy n:\\n {n}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ua3oqc6QAAcB",
        "outputId": "7dea8eea-92aa-4cbf-d6d6-c2e246275df7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor t:\n",
            " tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
            "numpy n:\n",
            " [2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------------------------------------------------\n",
        "#### [5] Exercise\n",
        "\n",
        "#### * [5-1] torch.cat 을 이용해서, (8,4) 크기의 텐서를 생성해봅시다.\n",
        "\n",
        " 힌트 : answer = torch.cat([tensor, tensor], dim=1)\n",
        "\n",
        "\n",
        "이때, tensor의 크기와 dim에 알맞는 수를 넣어야합니다.\n",
        "\n",
        "row, col, concat_dim에 알맞는 정수를 입력하세요.\n",
        "\n",
        "\n",
        "```\n",
        "# 원하는 결과\n",
        "torch.Size([8, 4])\n",
        "tensor([[1., 1., 1., 1.],\n",
        "        [1., 1., 1., 1.],\n",
        "        [1., 1., 1., 1.],\n",
        "        [1., 1., 1., 1.],\n",
        "        [1., 1., 1., 1.],\n",
        "        [1., 1., 1., 1.],\n",
        "        [1., 1., 1., 1.],\n",
        "        [1., 1., 1., 1.]])\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "GEUoQasWACpr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "row = ? # 알맞는 수를 입력하세요\n",
        "col = ? # 알맞는 수를 입력하세요\n",
        "concat_dim = ? # 알맞는 수를 입력하세요 (0 또는 1)\n",
        "\n",
        "tensor = torch.ones(row,col)\n",
        "print(tensor.shape)\n",
        "print(tensor)\n",
        "\n",
        "answer = torch.cat([tensor, tensor], dim=concat_dim)\n",
        "print(answer.shape)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lsrK-aERBPS",
        "outputId": "1d4b04fc-f5fd-4162-9521-a2df5c97d15c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 4])\n",
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n",
            "torch.Size([8, 4])\n",
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### * [5-2] 텐서의 dimension을 바꿔봅시다.\n",
        "\n",
        "텐서 a의 크기는 (1,2,4,5,1)입니다. (1,2,1,4,5)로 바꿔봅시다.\n",
        "힌트 : squeeze 연산을 통해 (1,2,4,5) 크기로 변환한 후,\n",
        " unsqueeze 연산으로 dimension을 추가해서 (1,2,1,4,5)를 만듭니다."
      ],
      "metadata": {
        "id": "qWs9vtChSerV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.Tensor(1,2,4,5,1)\n",
        "print(a.shape)\n",
        "\n",
        "# 물음표에 알맞은 수를 넣어주세요.\n",
        "a = torch.squeeze(a, dim=?) # 이 곳을 수정하시면 됩니다.\n",
        "print(a.shape)\n",
        "\n",
        "a = torch.unsqueeze(a, dim=?) # 이 곳을 수정하시면 됩니다.\n",
        "print(a.shape)"
      ],
      "metadata": {
        "id": "iFEbPpatSp1L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30280edb-3397-4a8d-cf15-2b6fc9f7e83c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 2, 4, 5, 1])\n",
            "torch.Size([1, 2, 4, 5])\n",
            "torch.Size([1, 2, 1, 4, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (+alpha) 간단한 Torch Model 만들기\n",
        "\n"
      ],
      "metadata": {
        "id": "AFKPcxBuaYAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 클래스 생성\n",
        "class LinearModel(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear = torch.nn.Linear(4,1, bias=False)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.linear(x)\n",
        "\n",
        "model = LinearModel()"
      ],
      "metadata": {
        "id": "E7-Urgh8akQw"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 파라미터 확인\n",
        "for name, param in model.named_parameters():\n",
        "  print(name, param)"
      ],
      "metadata": {
        "id": "vVLk9TMX-GN6",
        "outputId": "2d2ad531-ed5b-4c34-be34-77e3d6e999b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "linear.weight Parameter containing:\n",
            "tensor([[ 0.0663, -0.0381, -0.1189,  0.1286]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 총 10개의 랜덤 데이터 생성\n",
        "X = torch.randn(10, 4)  \n",
        "Y = 0.4 * X[:,0] + 0.3 * X[:,1] + 0.2 * X[:,2] + 0.1 * X[:,3]\n",
        "print(X)\n",
        "print(Y)"
      ],
      "metadata": {
        "id": "BYp7CWSu_RJk",
        "outputId": "1974dc6d-a460-43b4-c14b-381c6e12651b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.7928,  0.5828, -0.5254,  0.8026],\n",
            "        [-0.0308, -0.2144,  1.4066, -1.9018],\n",
            "        [-1.7279, -1.1837, -1.5208, -0.2449],\n",
            "        [-0.8197, -1.2801, -0.1967,  0.7482],\n",
            "        [-1.5260,  0.3668,  1.3715, -0.6843],\n",
            "        [-0.6542, -0.3921,  0.0151, -0.2636],\n",
            "        [ 0.6997,  1.0198,  0.4306, -1.1121],\n",
            "        [-0.3403, -0.0662, -1.4638,  1.4606],\n",
            "        [-0.3518, -0.3675, -0.8109,  0.3569],\n",
            "        [ 0.7636, -0.2509,  0.6317, -1.4793]])\n",
            "tensor([ 0.4671,  0.0145, -1.3749, -0.6764, -0.2945, -0.4027,  0.5607, -0.3027,\n",
            "        -0.3774,  0.2086])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 셋업 및 학습\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.05)\n",
        "\n",
        "for epoch in range(300):\n",
        "  y_pred = model(X)\n",
        "  loss = criterion(Y, y_pred.flatten())\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  if epoch % 10 == 9 :\n",
        "    print('epoch {} loss : '.format(epoch), loss.item())"
      ],
      "metadata": {
        "id": "qyjKa69AAuX8",
        "outputId": "5c8ea9ac-05f7-41fa-b787-134c5da10a7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 9 loss :  0.03308200091123581\n",
            "epoch 19 loss :  0.005225374363362789\n",
            "epoch 29 loss :  0.001664559356868267\n",
            "epoch 39 loss :  0.0007607939187437296\n",
            "epoch 49 loss :  0.0003914849366992712\n",
            "epoch 59 loss :  0.000207873250474222\n",
            "epoch 69 loss :  0.00011149103374918923\n",
            "epoch 79 loss :  6.015827602823265e-05\n",
            "epoch 89 loss :  3.266160638304427e-05\n",
            "epoch 99 loss :  1.7865577319753356e-05\n",
            "epoch 109 loss :  9.86289705906529e-06\n",
            "epoch 119 loss :  5.506282832357101e-06\n",
            "epoch 129 loss :  3.1154468160821125e-06\n",
            "epoch 139 loss :  1.7903657862916589e-06\n",
            "epoch 149 loss :  1.0469957487657666e-06\n",
            "epoch 159 loss :  6.240385914679791e-07\n",
            "epoch 169 loss :  3.793970222432108e-07\n",
            "epoch 179 loss :  2.353863663984157e-07\n",
            "epoch 189 loss :  1.488611331978973e-07\n",
            "epoch 199 loss :  9.587448346337624e-08\n",
            "epoch 209 loss :  6.273479158380724e-08\n",
            "epoch 219 loss :  4.164505895687398e-08\n",
            "epoch 229 loss :  2.7979254468846193e-08\n",
            "epoch 239 loss :  1.8981230809345107e-08\n",
            "epoch 249 loss :  1.2981267616396508e-08\n",
            "epoch 259 loss :  8.931889894370215e-09\n",
            "epoch 269 loss :  6.176895883669431e-09\n",
            "epoch 279 loss :  4.2896184382357205e-09\n",
            "epoch 289 loss :  2.988484792965096e-09\n",
            "epoch 299 loss :  2.085289052544681e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 후 모델 파라미터 확인\n",
        "for name, param in model.named_parameters():\n",
        "  print(name, param)"
      ],
      "metadata": {
        "id": "9_trylBlCBXi",
        "outputId": "def1f759-6007-4cf6-b636-d1a1160fced4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "linear.weight Parameter containing:\n",
            "tensor([[0.4000, 0.3001, 0.1999, 0.1000]], requires_grad=True)\n"
          ]
        }
      ]
    }
  ]
}